{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo\n",
    "import nengo_spa as spa\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "\n",
    "use_ocl = True\n",
    "if use_ocl:\n",
    "    import nengo_ocl\n",
    "    simulator = nengo_ocl.Simulator\n",
    "else:\n",
    "    simulator = nengo.Simulator\n",
    "    \n",
    "import sys, os\n",
    "\n",
    "sys.path.append('..')\n",
    "import experiments as xps\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "%matplotlib inline\n",
    "default_cycler = cycler('color', ['#006BA4', '#FF800E', '#ABABAB', '#595959', '#5F9ED1', '#C85200', '#898989', '#A2C8EC', '#FFBC79', '#CFCFCF'])\n",
    "plt.rc('axes', prop_cycle=(default_cycler))\n",
    "\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: setting random seed\n",
      "number_of_learning_trials 0\n",
      "number_of_non_learning_trials 600\n",
      "number_of_total_trials 600\n",
      "T 1217.39999\n"
     ]
    }
   ],
   "source": [
    "if True: # random seed\n",
    "    seed = np.random.randint(999)\n",
    "    print(\"Warning: setting random seed\")\n",
    "else:\n",
    "    seed = 1\n",
    "    \n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "s = spa.sym\n",
    "D = 128*1  # the dimensionality of the vectors\n",
    "D_GW = 128*2  # the dimensionality of the vectors in GW\n",
    "GW_THR = .2\n",
    "AM_THR = .2\n",
    "AM_function = lambda x: x#x>0\n",
    "AM_cls = spa.ThresholdingAssocMem # either WTAAssocMem or ThresholdingAssocMem\n",
    "ROUTING_THR = .25\n",
    "ROUTING_BIAS = .5\n",
    "model_source = [\"processors\",\"GW\"][1]\n",
    "\n",
    "# Number of neurons (per dimension or ensemble)\n",
    "scale_npds = 1\n",
    "npd_AM = int(50*scale_npds) # Default: 50\n",
    "npd_state = int(50*scale_npds) # Default: 50\n",
    "npd_BG = int(100*scale_npds) # Default: 100\n",
    "npd_thal1 = int(50*scale_npds) # Default: 50\n",
    "npd_thal2 = int(40*scale_npds) # Default: 40\n",
    "n_scalar = int(50*scale_npds) # Default: 50\n",
    "\n",
    "n_blocks_per_operation = 10 # default: 10\n",
    "n_trials_per_digit = 5 # default: 5\n",
    "n_different_digits = 4 # default: 4\n",
    "n_different_operations = 3 # default: 3\n",
    "\n",
    "number_of_total_trials = n_blocks_per_operation * n_trials_per_digit * n_different_digits * n_different_operations\n",
    "number_of_non_learning_trials = number_of_total_trials\n",
    "number_of_learning_trials = max(0,number_of_total_trials - number_of_non_learning_trials)\n",
    "print(\"number_of_learning_trials\",number_of_learning_trials) \n",
    "print(\"number_of_non_learning_trials\",number_of_non_learning_trials) \n",
    "print(\"number_of_total_trials\",number_of_total_trials)\n",
    "\n",
    "\n",
    "add_ON = '+ON'\n",
    "keys = ['TWO','FOUR','SIX','EIGHT','X', \\\n",
    "               'MORE','LESS', \\\n",
    "    'G', 'V', 'COM', 'ADD', 'SUB', \\\n",
    "    'SIMPLE', 'CHAINED_ADD', 'CHAINED_SUB', \\\n",
    "               'ON'\n",
    "    ] + ['V_COM', 'COM_PM', 'V_ADD', 'V_SUB', 'ADD_COM', 'SUB_COM']\n",
    "\n",
    "vocab = spa.Vocabulary(dimensions=D, pointer_gen=np.random.RandomState(seed))\n",
    "vocab_GW = spa.Vocabulary(dimensions=D_GW, pointer_gen=np.random.RandomState(seed))\n",
    "\n",
    "for voc in [vocab, vocab_GW]:\n",
    "    voc.populate(\";\".join(keys))\n",
    "vocab_GW.populate(\";\".join([p+\"_ON=ON*\"+p for p in ['V', 'COM', 'ADD', 'SUB']])) # this is done to avoid similarity with other SPs\n",
    "\n",
    "trials = xps.createTrials(n_blocks_per_operation, n_trials_per_digit, n_different_digits, n_different_operations, shuffle=True)\n",
    "xp = xps.Xp1(number_of_learning_trials, trials, fixation=\"0\")\n",
    "#xp = xps.TestMasking(.083, number_of_learning_trials, trials, fixation=\"0\")\n",
    "\n",
    "T = number_of_total_trials * xp.trial_length - .00001# simulations run a bit too long\n",
    "print('T',T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "model = spa.Network(seed=seed)\n",
    "with model:\n",
    "    \n",
    "    model.config[spa.State].neurons_per_dimension = npd_state\n",
    "    model.config[spa.Scalar].n_neurons = n_scalar\n",
    "    model.config[spa.BasalGanglia].n_neurons_per_ensemble = npd_BG\n",
    "    model.config[spa.Thalamus].neurons_action = npd_thal1\n",
    "    model.config[spa.Thalamus].neurons_channel_dim = npd_thal1\n",
    "    model.config[spa.Thalamus].neurons_gate = npd_thal2\n",
    "\n",
    "    # We start defining the buffer slots in which information can\n",
    "    # be placed:\n",
    "    \n",
    "    # A slot for the goal/task\n",
    "    G = spa.State(vocab, label='G')\n",
    "    \n",
    "    # A slot for the visual input (the digit N). Feedback is used for iconic memory (100-300ms)\n",
    "    RETINA = spa.WTAAssocMem(\n",
    "        0.1,\n",
    "        vocab,\n",
    "        mapping={k:k+add_ON for k in ['TWO','FOUR','SIX','EIGHT','X']},\n",
    "        #mapping=['TWO','FOUR','SIX','EIGHT','X'],\n",
    "        function=lambda x: x>0,\n",
    "        n_neurons = npd_AM\n",
    "    )\n",
    "    nengo.Connection(RETINA.input, RETINA.input, transform=.85, synapse=.005)\n",
    "    V = spa.State(vocab, label='V')\n",
    "    nengo.Connection(RETINA.output, V.input, synapse=.055)    \n",
    "    \n",
    "    # A slot for the action (MORE or LESS)\n",
    "    PM = spa.State(vocab, feedback=.8, feedback_synapse=.05, label='PM')\n",
    "    with nengo.Network() as ACT_net:\n",
    "        ACT_net.config[nengo.Ensemble].neuron_type = nengo.Direct()\n",
    "        ACT = spa.State(vocab, label='ACT direct')\n",
    "\n",
    "    # An associative memory for the + operation\n",
    "    ADD_input = spa.State(vocab, feedback=.85, feedback_synapse=.05, label='ADD_input')\n",
    "    ADD = AM_cls(threshold=AM_THR, \n",
    "        input_vocab=vocab, mapping=\n",
    "        {\n",
    "            'TWO':'FOUR'+add_ON,\n",
    "            'FOUR':'SIX'+add_ON,\n",
    "            'SIX':'EIGHT'+add_ON,\n",
    "            'EIGHT':'TWO'+add_ON,\n",
    "        },\n",
    "        function=AM_function,\n",
    "        label='ADD',\n",
    "        n_neurons = npd_AM\n",
    "    )\n",
    "    ADD_input >> ADD.input\n",
    "    \n",
    "    # An associative memory for the - operation\n",
    "    SUB_input = spa.State(vocab, feedback=.85, feedback_synapse=.05, label='SUB_input')\n",
    "    SUB = AM_cls(threshold=AM_THR, \n",
    "        input_vocab=vocab, mapping=\n",
    "        {\n",
    "            'TWO':'EIGHT'+add_ON,\n",
    "            'FOUR':'TWO'+add_ON,\n",
    "            'SIX':'FOUR'+add_ON,\n",
    "            'EIGHT':'SIX'+add_ON,\n",
    "        },\n",
    "        function=AM_function,\n",
    "        label='SUB',\n",
    "        n_neurons = npd_AM\n",
    "    )\n",
    "    SUB_input >> SUB.input\n",
    "    \n",
    "    # An associative memory for the \"compare to 5\" operation\n",
    "    COM_input = spa.State(vocab, feedback=.85, feedback_synapse=.05, label='COM_input')\n",
    "    COM = AM_cls(threshold=AM_THR, \n",
    "        input_vocab=vocab, mapping=\n",
    "        {\n",
    "            'TWO':'LESS'+add_ON,\n",
    "            'FOUR':'LESS'+add_ON,\n",
    "            'SIX':'MORE'+add_ON,\n",
    "            'EIGHT':'MORE'+add_ON,\n",
    "        },\n",
    "        function=AM_function,\n",
    "        label='COM',\n",
    "        n_neurons = npd_AM\n",
    "    )\n",
    "    COM_input >> COM.input\n",
    "\n",
    "    # A slot that combines selected information from the processors\n",
    "    GW = spa.State(vocab_GW, label='GW', feedback=.75)\n",
    "    \n",
    "    processors = [V, ADD, SUB, COM]\n",
    "    competition_keys = {\n",
    "        G: ['SIMPLE', 'CHAINED_ADD', 'CHAINED_SUB'],\n",
    "        V: ['TWO','FOUR','SIX','EIGHT','X'],\n",
    "        ADD: ['TWO','FOUR','SIX','EIGHT'],\n",
    "        SUB: ['TWO','FOUR','SIX','EIGHT'],\n",
    "        COM: ['MORE','LESS'],\n",
    "    }\n",
    "    preconscious = {}\n",
    "    filters = {}\n",
    "    \n",
    "    for proc in processors:\n",
    "        \n",
    "        preconscious[proc] = proc\n",
    "        \n",
    "        filters[proc] = spa.modules.WTAAssocMem(\n",
    "            GW_THR,\n",
    "            vocab,\n",
    "            mapping={k:k+add_ON for k in competition_keys[proc]},\n",
    "            function=lambda x: x>0,\n",
    "            n_neurons = npd_AM,\n",
    "            label=\"filter \"+proc.label\n",
    "        )\n",
    "        preconscious[proc] >> filters[proc].input\n",
    "        \n",
    "        nengo.Connection(filters[proc].output, GW.input, \n",
    "            transform=\n",
    "                     np.dot(\n",
    "                         vocab_GW.parse(proc.label).get_binding_matrix(), \n",
    "                         vocab.transform_to(vocab_GW)\n",
    "                     ))\n",
    "    \n",
    "    conscious_conditions = { # bottom-up strength * top-down attention\n",
    "        V:   ROUTING_BIAS+spa.dot(preconscious[V]  .output, s.ON) * (1-spa.dot(filters[COM], s.ON)-spa.dot(filters[ADD], s.ON)-spa.dot(filters[SUB], s.ON)),\n",
    "        ADD: ROUTING_BIAS+spa.dot(preconscious[ADD].output, s.ON) * (1-spa.dot(filters[COM], s.ON)),\n",
    "        SUB: ROUTING_BIAS+spa.dot(preconscious[SUB].output, s.ON) * (1-spa.dot(filters[COM], s.ON)),\n",
    "        COM: ROUTING_BIAS+spa.dot(preconscious[COM].output, s.ON)\n",
    "    }\n",
    "    access_labels = []\n",
    "    with spa.Network(label='conscious access') :\n",
    "        with spa.ActionSelection() as access:\n",
    "            for proc in processors:\n",
    "                access_labels.append(proc.label)\n",
    "                spa.ifmax(proc.label, conscious_conditions[proc],\n",
    "                            preconscious[proc] >> filters[proc],\n",
    "                         )\n",
    "            access_labels.append(\"Thresholder\")\n",
    "            spa.ifmax(ROUTING_BIAS+ROUTING_THR)\n",
    "    \n",
    "    \"\"\"# Add G to GW\n",
    "    nengo.Connection(G.output, GW.input, \n",
    "            transform=\n",
    "                         np.dot(\n",
    "                             vocab_GW.parse(G.label).get_binding_matrix(), \n",
    "                             vocab.transform_to(vocab_GW)\n",
    "                         ))\"\"\"\n",
    "    \n",
    "                                                                                                         \n",
    "                                                                                                         \n",
    "    # Create the inputs\n",
    "    with spa.Network(label='inputs'):\n",
    "        RETINA_input = spa.Transcode(xp.RETINA_input,output_vocab = vocab)\n",
    "        G_input = spa.Transcode(xp.G_input, output_vocab = vocab)\n",
    "\n",
    "    nengo.Connection(RETINA_input.output, RETINA.input, synapse=None)\n",
    "    G_input >> G\n",
    "    \n",
    "    if model_source == \"GW\":\n",
    "        sources = {proc:spa.State(vocab, label='broadcast source '+proc.label) for proc in processors}\n",
    "        for proc in sources.keys():\n",
    "            nengo.Connection(GW.output, sources[proc].input, transform=\n",
    "                             np.dot(\n",
    "                                 vocab_GW.transform_to(vocab, populate=False),\n",
    "                                 vocab_GW.parse(\"~\"+proc.label).get_binding_matrix()\n",
    "                             ))\n",
    "    elif model_source == \"processors\":\n",
    "        sources = {proc:proc if isinstance(proc,spa.State) else proc.output for proc in processors}\n",
    "    action_labels = []\n",
    "    with spa.Network(label='broadcast') :\n",
    "        with spa.ActionSelection() as broadcast:\n",
    "\n",
    "            action_labels.append(\"V_COM\")\n",
    "            spa.ifmax(\"V_COM\", ROUTING_BIAS+spa.dot(filters[V], s.ON) * spa.dot(G, s.SIMPLE),\n",
    "                        sources[V] >> COM_input,\n",
    "                     )\n",
    "            \n",
    "            action_labels.append(\"V_SUB\")\n",
    "            spa.ifmax(\"V_SUB\", ROUTING_BIAS+spa.dot(filters[V], s.ON) * spa.dot(G, s.CHAINED_SUB),\n",
    "                        sources[V] >> SUB_input,\n",
    "                     )\n",
    "\n",
    "            action_labels.append(\"V_ADD\")\n",
    "            spa.ifmax(\"V_ADD\", ROUTING_BIAS+spa.dot(filters[V], s.ON) * spa.dot(G, s.CHAINED_ADD),\n",
    "                        sources[V] >> ADD_input,\n",
    "                     )\n",
    "\n",
    "            action_labels.append(\"ADD_COM\")\n",
    "            spa.ifmax(\"ADD_COM\", ROUTING_BIAS+spa.dot(filters[ADD], s.ON),\n",
    "                        sources[ADD] >> COM_input,\n",
    "                     )\n",
    "               \n",
    "            action_labels.append(\"SUB_COM\")\n",
    "            spa.ifmax(\"SUB_COM\", ROUTING_BIAS+spa.dot(filters[SUB], s.ON),\n",
    "                        sources[SUB] >> COM_input,\n",
    "                     )\n",
    "                \n",
    "            action_labels.append(\"COM_PM\")\n",
    "            spa.ifmax(\"COM_PM\", ROUTING_BIAS+spa.dot(filters[COM], s.ON),\n",
    "                        sources[COM] >> PM,\n",
    "                     )            \n",
    "            \n",
    "            action_labels.append(\"Thresholder\")\n",
    "            spa.ifmax(\"Thresholder\", ROUTING_BIAS+ROUTING_THR) # Threshold for action\n",
    "    \n",
    "    \n",
    "    with spa.Network(label='Action'):\n",
    "        with spa.ActionSelection():            \n",
    "                spa.ifmax( spa.dot(PM, s.MORE),\n",
    "                            s.MORE >> ACT)\n",
    "                spa.ifmax( spa.dot(PM, s.LESS),\n",
    "                            s.LESS >> ACT)\n",
    "\n",
    "                spa.ifmax( .3)\n",
    "            \n",
    "    BTN = nengo.Node(xps.Button([vocab.parse('MORE').v, vocab.parse('LESS').v], xp.trial_length), size_in=D)\n",
    "    nengo.Connection(ACT.output, BTN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    \n",
    "    probe_dt = .05\n",
    "    probe_synapse = .015\n",
    "#     p_V = nengo.Probe(V.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "#     p_G = nengo.Probe(G.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "\n",
    "#     p_GW = nengo.Probe(GW.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "\n",
    "#     p_ADD = nengo.Probe(ADD.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "#     p_SUB = nengo.Probe(SUB.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "#     p_COM = nengo.Probe(COM.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    \n",
    "#     p_PM = nengo.Probe(PM.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "#     p_ACT = nengo.Probe(ACT.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    p_BTN = nengo.Probe(BTN)#, sample_every = probe_dt)\n",
    "    \n",
    "#     p_broadcast_in = nengo.Probe(broadcast.bg.input, synapse = probe_synapse)\n",
    "#     p_broadcast_out = nengo.Probe(broadcast.bg.output, synapse = probe_synapse)\n",
    "#     p_access_in = nengo.Probe(access.bg.input, synapse = probe_synapse)\n",
    "#     p_access_out = nengo.Probe(access.bg.output, synapse = probe_synapse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of neurons: 158650\n",
      "T: 1217.39999\n",
      "No context argument was provided to nengo_ocl.Simulator\n",
      "Calling pyopencl.create_some_context() for you now:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id=\"de70e21e-e124-40f8-b04c-b6a58a160182\" style=\"\n",
       "                    width: 100%;\n",
       "                    border: 1px solid #cfcfcf;\n",
       "                    border-radius: 4px;\n",
       "                    text-align: center;\n",
       "                    position: relative;\">\n",
       "                  <div class=\"pb-text\" style=\"\n",
       "                      position: absolute;\n",
       "                      width: 100%;\">\n",
       "                    0%\n",
       "                  </div>\n",
       "                  <div class=\"pb-fill\" style=\"\n",
       "                      background-color: #bdd2e6;\n",
       "                      width: 0%;\">\n",
       "                    <style type=\"text/css\" scoped=\"scoped\">\n",
       "                        @keyframes pb-fill-anim {\n",
       "                            0% { background-position: 0 0; }\n",
       "                            100% { background-position: 100px 0; }\n",
       "                        }\n",
       "                    </style>\n",
       "                    &nbsp;\n",
       "                  </div>\n",
       "                </div>"
      ],
      "text/plain": [
       "HtmlProgressBar cannot be displayed. Please use the TerminalProgressBar. It can be enabled with `nengo.rc.set('progress', 'progress_bar', 'nengo.utils.progress.TerminalProgressBar')`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "              (function () {\n",
       "                  var root = document.getElementById('de70e21e-e124-40f8-b04c-b6a58a160182');\n",
       "                  var text = root.getElementsByClassName('pb-text')[0];\n",
       "                  var fill = root.getElementsByClassName('pb-fill')[0];\n",
       "\n",
       "                  text.innerHTML = 'Simulation finished in 0:40:23.';\n",
       "                  \n",
       "            if (100.0 > 0.) {\n",
       "                fill.style.transition = 'width 0.1s linear';\n",
       "            } else {\n",
       "                fill.style.transition = 'none';\n",
       "            }\n",
       "\n",
       "            fill.style.width = '100.0%';\n",
       "            fill.style.animation = 'none';\n",
       "            fill.style.backgroundImage = 'none'\n",
       "        \n",
       "                  \n",
       "                fill.style.animation = 'none';\n",
       "                fill.style.backgroundImage = 'none';\n",
       "            \n",
       "              })();\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = .001\n",
    "print(\"Number of neurons:\", model.n_neurons)\n",
    "print(\"T:\",T)\n",
    "with simulator(model, dt = dt, seed=seed) as sim:\n",
    "    sim.run(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    \n",
    "    def plot_similarities(t_range, data, vocab, keys=False, autoscale=False, title='Similarity', sort_legend=True, permutation=None, subplot_nrows=0, subplot_ncols=0, subplot_i = 1):\n",
    "\n",
    "        if not keys:\n",
    "            keys = list(vocab.keys())\n",
    "\n",
    "        if subplot_nrows * subplot_ncols > 0:\n",
    "            plt.subplot(subplot_nrows,subplot_ncols,subplot_i)\n",
    "\n",
    "        if permutation is None:\n",
    "            permutation = range(vocab.dimensions)\n",
    "        vectors = np.array([vocab.parse(p).v @ np.identity(vocab.dimensions)[permutation] for p in keys])\n",
    "        mean_activation = spa.similarity(data, vectors).mean(axis=0)\n",
    "        sort_idx = np.argsort(mean_activation)[::-1]    \n",
    "\n",
    "        ymin, ymax = -1.5, 1.5\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.autoscale(autoscale, axis='y')\n",
    "        plt.grid(True)\n",
    "        plt.plot(t_range, spa.similarity(data, vectors[sort_idx]), linewidth=2.5)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Similarity\")\n",
    "        plt.xlim(left=t_range[0], right=t_range[-1])\n",
    "        plt.xticks(np.arange(t_range[0], t_range[-1], xp.trial_length))\n",
    "        leg = plt.legend([str(round(mean_activation[sort_idx][i],2))+' '+k for i,k in enumerate(np.array(keys)[sort_idx])], loc='upper center',\n",
    "                   bbox_to_anchor=(0.5, -0.13), ncol=3)\n",
    "        \n",
    "        # set the linewidth of each legend object\n",
    "        for legobj in leg.legendHandles:\n",
    "            legobj.set_linewidth(4.0)\n",
    "            \n",
    "        if subplot_nrows * subplot_ncols == 0:\n",
    "            plt.show()\n",
    "\n",
    "        return subplot_i + 1\n",
    "\n",
    "\n",
    "\n",
    "    subplot_nrows=9\n",
    "    subplot_ncols=1\n",
    "    plt.figure(figsize=(6*subplot_ncols,4.5*subplot_nrows))\n",
    "    \n",
    "    def trial_t(trial_number):\n",
    "        return trial_number*xp.trial_length\n",
    "    \n",
    "    start = trial_t(0)\n",
    "    end = trial_t(4)\n",
    "    skip = 5\n",
    "    trange = sim.trange()\n",
    "    selected_idx = np.where(np.logical_and(trange > start, trange < end))\n",
    "    trange = trange[selected_idx][::skip]\n",
    "\n",
    "\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_V][selected_idx][::skip], vocab, keys=['TWO','FOUR','SIX','EIGHT', 'ON','X'], title='V', subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_G][selected_idx][::skip], vocab, keys=['SIMPLE','CHAINED_SUB','CHAINED_ADD'], title='G', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_ADD][selected_idx][::skip], vocab, keys=['TWO','FOUR','SIX','EIGHT','ON','X'], title='ADD', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_SUB][selected_idx][::skip], vocab, keys=['TWO','FOUR','SIX','EIGHT','ON','X'], title='SUB', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_COM][selected_idx][::skip], vocab, keys=['MORE','LESS','ON'], title='COM', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_PM][selected_idx][::skip], vocab, keys=['MORE','LESS','ON'], title='PM', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_ACT][selected_idx][::skip], vocab, keys=['MORE','LESS','ON'], title='ACT', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_GW][selected_idx][::skip], vocab_GW, keys=[p+\"*ON\" for p in [\"G\", \"V\", \"ADD\", \"SUB\", \"COM\"]], title='GW', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "\n",
    "    trange = sim.trange()[selected_idx]\n",
    "    plt.subplot(subplot_nrows,subplot_ncols,subplot_i)\n",
    "    plt.plot(trange, sim.data[p_BTN][selected_idx], color='black', linewidth=3.5)\n",
    "    plt.xlim(left=trange[0], right=trange[-1])\n",
    "    plt.xticks(np.arange(trange[0], trange[-1], xp.trial_length))\n",
    "    plt.ylim(-.2,2.2)\n",
    "    plt.ylabel(\"Action\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ded2e1dfc4d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_broadcast_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'selected_idx' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "for i in range(broadcast.bg.input.size_out):\n",
    "    plt.subplot(1,broadcast.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_broadcast_in][:,i][selected_idx][::skip])\n",
    "    plt.title(action_labels[i])\n",
    "    plt.ylim(-.5,1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "for i in range(broadcast.bg.input.size_out):\n",
    "    plt.subplot(1,broadcast.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_broadcast_out][:,i][selected_idx][::skip])\n",
    "    plt.title(action_labels[i])\n",
    "    plt.ylim(-1.5,.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "for i in range(access.bg.input.size_out):\n",
    "    plt.subplot(1,access.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_access_in][:,i][selected_idx][::skip])\n",
    "    plt.title(access_labels[i])\n",
    "    plt.ylim(-.5,1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "for i in range(access.bg.input.size_out):\n",
    "    plt.subplot(1,access.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_access_out][:,i][selected_idx][::skip])\n",
    "    plt.title(access_labels[i])\n",
    "    plt.ylim(-1.5,.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_key_to_int = {'TWO':2, 'FOUR':4, 'SIX':6, 'EIGHT':8}\n",
    "digit_key_to_idx = {k:i for i,k in enumerate(digit_key_to_int.keys())}\n",
    "operations_key_to_idx = {k:i for i,k in enumerate(['SIMPLE', 'CHAINED_ADD', 'CHAINED_SUB'])}\n",
    "\n",
    "n_per_condition = n_blocks_per_operation * n_trials_per_digit\n",
    "\n",
    "RTs = np.zeros((n_different_operations, n_different_digits, n_per_condition)) \n",
    "performance = np.zeros((n_different_operations, n_different_digits, n_per_condition)) # 0:no answer / 1:wrong answer / 2:correct answer\n",
    "xp_errors = []\n",
    "\n",
    "indices = np.zeros((n_different_operations, n_different_digits), dtype=int) \n",
    "\n",
    "\n",
    "def get_expected_action(trial):\n",
    "    N = digit_key_to_int[trial.stimulus] \n",
    "    if trial.operation == 'CHAINED_ADD':\n",
    "        N += 2\n",
    "    elif trial.operation == 'CHAINED_SUB':\n",
    "        N -= 2\n",
    "    if N > 8:\n",
    "        N = 2\n",
    "    elif N < 2:\n",
    "        N = 8\n",
    "    expected_action = 1 + int(not N > 5)\n",
    "    return expected_action\n",
    "\n",
    "t = 0\n",
    "while t<T-.01:\n",
    "    t += xp.trial_length\n",
    "    trial = xp(t)[0]\n",
    "    expected_action = get_expected_action(trial)\n",
    "    t_window = (np.where(np.logical_and(sim.trange() < t, sim.trange() > t-xp.trial_length))[0],)\n",
    "    \n",
    "    # get model's action\n",
    "    model_behaviour = sim.data[p_BTN][t_window]\n",
    "    if np.count_nonzero(model_behaviour) > 1:\n",
    "        raise ValueError(\"more than one action\")\n",
    "    \n",
    "    \n",
    "    cond_idx = (operations_key_to_idx[trial.operation], digit_key_to_idx[trial.stimulus])\n",
    "    trial_idx = indices[cond_idx]\n",
    "    \n",
    "    model_action = model_behaviour.sum()\n",
    "    if model_action == 0:\n",
    "        trial_RT = 0\n",
    "        trial_performance = 0\n",
    "    else:\n",
    "        action_t_idx = np.nonzero(model_behaviour[:,0])\n",
    "        trial_RT = sim.trange()[t_window][action_t_idx][0] - (t-xp.trial_length) - xp.t_start\n",
    "        trial_performance = int(model_action==expected_action) + 1\n",
    "    \n",
    "    xp_errors += [trial_performance!=2]\n",
    "    \n",
    "    performance[cond_idx+(trial_idx,)] = trial_performance\n",
    "    RTs[cond_idx+(trial_idx,)] = trial_RT\n",
    "    \n",
    "    indices[cond_idx] += 1 # increment index of this condition\n",
    "    \n",
    "\n",
    "\n",
    "xp_errors = np.array(xp_errors, dtype=bool)\n",
    "\n",
    "plt.figure(figsize=(8,1))\n",
    "plt.eventplot(np.where(xp_errors), color='black')\n",
    "plt.yticks([])\n",
    "plt.ylabel('Error')\n",
    "plt.xlim(-1,len(xp_errors)+1)\n",
    "plt.title('Score: '+str(number_of_total_trials-xp_errors.sum())+'/'+str(number_of_total_trials)+\"\\n\"+\n",
    "         \"error rate: \"+str(round(100*xp_errors.sum()/number_of_total_trials,2))+\"%\")\n",
    "plt.xlabel('Trial')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(indices)\n",
    "# print(RTs)\n",
    "print(performance.shape)\n",
    "print(performance[2,1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple blocks plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RTs_simple = np.copy(RTs[0,:,:]) * 1000\n",
    "RTs_simple = [RTs_simple[i,:] for i in range(n_different_digits)]\n",
    "print(RTs_simple)\n",
    "for digit_RTs in RTs_simple:\n",
    "#     print(digit_RTs.shape)\n",
    "    digit_RTs = digit_RTs[digit_RTs != 0] # remove outliers (no answer)\n",
    "#     print(digit_RTs.shape)\n",
    "#     print('\\n')\n",
    "\n",
    "RTs_simple_median = np.array([np.median(digit_RTs) for digit_RTs in RTs_simple])\n",
    "RTs_simple_std = np.array([digit_RTs.std() for digit_RTs in RTs_simple])\n",
    "plt.errorbar([2,4,6,8][:n_different_digits], RTs_simple_median, yerr=RTs_simple_std, color='black', capsize=3, capthick=2, marker='.', markersize=12, markerfacecolor='white')\n",
    "plt.ylabel('Median Reaction times (ms)')\n",
    "plt.xlabel('Stimuli')\n",
    "plt.xticks([2,4,6,8][:n_different_digits])\n",
    "plt.show()\n",
    "\n",
    "print(RTs_simple_median)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for unresponsive_as_error in [False,True]:\n",
    "\n",
    "    if unresponsive_as_error:\n",
    "        performance_simple = np.copy(performance[0,:,:])\n",
    "        err_simple = np.sum(performance_simple != 2, axis=1) / n_per_condition * 100\n",
    "        plt.title('Errors and absence of response')\n",
    "        \n",
    "    else:\n",
    "        performance_simple = np.copy(performance[0,:,:])\n",
    "        n_responsive = np.sum(performance_simple!=0) # count the number of responses\n",
    "        err_simple = np.sum(performance_simple == 1, axis=1) / n_responsive * 100\n",
    "        plt.title('Errors')\n",
    "\n",
    "    plt.bar([2,4,6,8][:n_different_digits], err_simple, color='black')\n",
    "    plt.ylabel('Error rates (%)')\n",
    "    plt.xlabel('Stimuli')\n",
    "    plt.xticks([2,4,6,8][:n_different_digits])\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained blocks plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
