{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo\n",
    "import nengo_spa as spa\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import random\n",
    "\n",
    "\n",
    "use_ocl = True\n",
    "if use_ocl:\n",
    "    import nengo_ocl\n",
    "    simulator = nengo_ocl.Simulator\n",
    "else:\n",
    "    simulator = nengo.Simulator\n",
    "    \n",
    "import sys, os\n",
    "\n",
    "sys.path.append('..')\n",
    "import experiments as xps\n",
    "from modules import Processor\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "%matplotlib inline\n",
    "default_cycler = cycler('color', ['#006BA4', '#FF800E', '#ABABAB', '#595959', '#5F9ED1', '#C85200', '#898989', '#A2C8EC', '#FFBC79', '#CFCFCF'])\n",
    "plt.rc('axes', prop_cycle=(default_cycler))\n",
    "\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: setting random seed\n",
      "number_of_learning_trials 0\n",
      "number_of_non_learning_trials 6\n",
      "number_of_total_trials 6\n",
      "T 12.17399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=7, similarity=0.02)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=8, similarity=0.02)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=10, similarity=0.03)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=11, similarity=0.04)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=12, similarity=0.04)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=13, similarity=0.05)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=14, similarity=0.03)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=15, similarity=0.02)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=16, similarity=0.05)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=17, similarity=0.05)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=18, similarity=0.05)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=19, similarity=0.03)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=20, similarity=0.06)\n",
      "  len(self._key2idx), best_sim))\n",
      "/home/ubuntu/anaconda3/envs/CTN/lib/python3.7/site-packages/nengo_spa/vocabulary.py:173: UserWarning: Could not create a semantic pointer with max_similarity=0.02 (D=256, M=21, similarity=0.06)\n",
      "  len(self._key2idx), best_sim))\n"
     ]
    }
   ],
   "source": [
    "if True: # random seed\n",
    "    seed = np.random.randint(999)\n",
    "    print(\"Warning: setting random seed\")\n",
    "else:\n",
    "    seed = 1\n",
    "    \n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "s = spa.sym\n",
    "D = 128*2  # the dimensionality of the vectors\n",
    "D_GW = 128*2  # the dimensionality of the vectors in GW\n",
    "GW_THR = .2\n",
    "AM_THR = .2\n",
    "#AM_cls = spa.ThresholdingAssocMem # either WTAAssocMem or ThresholdingAssocMem\n",
    "PROC_FDBCK = .85\n",
    "GW_FDBCK = .85\n",
    "GW_THR = .5\n",
    "ROUTING_THR = .25\n",
    "ROUTING_BIAS = .5\n",
    "broadcast_source = [\"processors\",\"GW\"][1]\n",
    "\n",
    "# Number of neurons (per dimension or ensemble)\n",
    "scale_npds = 1\n",
    "npd_AM = int(50*scale_npds) # Default: 50\n",
    "npd_state = int(50*scale_npds) # Default: 50\n",
    "npd_BG = int(100*scale_npds) # Default: 100\n",
    "npd_thal1 = int(50*scale_npds) # Default: 50\n",
    "npd_thal2 = int(40*scale_npds) # Default: 40\n",
    "n_scalar = int(50*scale_npds) # Default: 50\n",
    "\n",
    "n_blocks_per_operation = 1 # default: 10\n",
    "n_trials_per_digit = 1 # default: 5\n",
    "n_different_digits = 2 # default: 4\n",
    "n_different_operations = 3 # default: 3\n",
    "\n",
    "number_of_total_trials = n_blocks_per_operation * n_trials_per_digit * n_different_digits * n_different_operations\n",
    "number_of_non_learning_trials = number_of_total_trials\n",
    "number_of_learning_trials = max(0,number_of_total_trials - number_of_non_learning_trials)\n",
    "print(\"number_of_learning_trials\",number_of_learning_trials) \n",
    "print(\"number_of_non_learning_trials\",number_of_non_learning_trials) \n",
    "print(\"number_of_total_trials\",number_of_total_trials)\n",
    "\n",
    "\n",
    "add_ON = True\n",
    "keys = ['TWO','FOUR','SIX','EIGHT','X', \\\n",
    "               'MORE','LESS', \\\n",
    "    'G', 'V', 'COM', 'ADD', 'SUB', \\\n",
    "    'SIMPLE', 'CHAINED_ADD', 'CHAINED_SUB', \\\n",
    "               'ON'\n",
    "    ] + ['V_COM', 'COM_PM', 'V_ADD', 'V_SUB', 'ADD_COM', 'SUB_COM']\n",
    "\n",
    "vocab = spa.Vocabulary(dimensions=D, pointer_gen=np.random.RandomState(seed), max_similarity=.02)\n",
    "vocab_GW = spa.Vocabulary(dimensions=D_GW, pointer_gen=np.random.RandomState(seed), max_similarity=.02)\n",
    "\n",
    "for voc in [vocab, vocab_GW]:\n",
    "    voc.populate(\";\".join(keys))\n",
    "vocab_GW.populate(\";\".join([p+\"_ON=(ON*\"+p+\").normalized()\" for p in ['V', 'COM', 'ADD', 'SUB']])) # this is done to avoid similarity with other SPs\n",
    "\n",
    "trials = xps.createTrials(n_blocks_per_operation, n_trials_per_digit, n_different_digits, n_different_operations, shuffle=True)\n",
    "xp = xps.Xp1(number_of_learning_trials, trials, fixation=\"0\")\n",
    "#xp = xps.TestMasking(.083, number_of_learning_trials, trials, fixation=\"0\")\n",
    "\n",
    "T = number_of_total_trials * xp.trial_length - .00001# simulations run a bit too long\n",
    "print('T',T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Processor' object has no attribute 'filter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a9e5f2908f54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mGW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# access network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Processor' object has no attribute 'filter'"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "model = spa.Network(seed=seed)\n",
    "with model:\n",
    "    \n",
    "    model.config[spa.State].neurons_per_dimension = npd_state\n",
    "    model.config[spa.Scalar].n_neurons = n_scalar\n",
    "    model.config[spa.BasalGanglia].n_neurons_per_ensemble = npd_BG\n",
    "    model.config[spa.Thalamus].neurons_action = npd_thal1\n",
    "    model.config[spa.Thalamus].neurons_channel_dim = npd_thal1\n",
    "    model.config[spa.Thalamus].neurons_gate = npd_thal2\n",
    "    \n",
    "    inputs_net = spa.Network(label='inputs')\n",
    "\n",
    "    # We start defining the buffer slots in which information can\n",
    "    # be placed:\n",
    "    \n",
    "    # A slot for the goal/task\n",
    "    G = spa.State(vocab, label='G')\n",
    "    with inputs_net:\n",
    "        G_input = spa.Transcode(xp.G_input, output_vocab = vocab)\n",
    "    G_input >> G\n",
    "    \n",
    "    # A slot for the visual input (the digit N). Feedback is used for iconic memory (100-300ms)\n",
    "    V_mapping = ['TWO','FOUR','SIX','EIGHT','X']\n",
    "    RETINA = spa.WTAAssocMem(\n",
    "        0.1,\n",
    "        vocab,\n",
    "        mapping=V_mapping,\n",
    "        function=lambda x: x>0,\n",
    "        n_neurons = npd_AM\n",
    "    )\n",
    "    with inputs_net:\n",
    "        RETINA_input = spa.Transcode(xp.RETINA_input,output_vocab = vocab)\n",
    "    nengo.Connection(RETINA_input.output, RETINA.input, synapse=None)\n",
    "        \n",
    "    V = Processor(\n",
    "        vocab, vocab_GW, 'V', V_mapping, filter_thr=GW_THR, feedback=PROC_FDBCK, add_ON=add_ON, \n",
    "        npd_AM=npd_AM, broadcast_source=broadcast_source, seed=seed\n",
    "    )\n",
    "    RETINA.output >> V.input_state\n",
    "    \n",
    "    # A slot for the action (MORE or LESS)\n",
    "    PM = spa.State(vocab, feedback=PROC_FDBCK, label='PM')\n",
    "    with spa.Network(label='Action'):\n",
    "        with nengo.Network() as ACT_net:\n",
    "            ACT_net.config[nengo.Ensemble].neuron_type = nengo.Direct()\n",
    "            ACT = spa.State(vocab, label='ACT direct')\n",
    "        with spa.ActionSelection():            \n",
    "                spa.ifmax( spa.dot(PM, s.MORE),\n",
    "                            s.MORE >> ACT)\n",
    "                spa.ifmax( spa.dot(PM, s.LESS),\n",
    "                            s.LESS >> ACT)\n",
    "                spa.ifmax( .3)\n",
    "            \n",
    "    BTN = nengo.Node(xps.Button([vocab.parse('MORE').v, vocab.parse('LESS').v], xp.trial_length), size_in=D)\n",
    "    nengo.Connection(ACT.output, BTN)\n",
    "\n",
    "    # An associative memory for the + operation\n",
    "    ADD = Processor(\n",
    "        vocab, vocab_GW, 'ADD', add_ON=add_ON,\n",
    "        AM_mapping = {\n",
    "            'TWO':'FOUR',\n",
    "            'FOUR':'SIX',\n",
    "            'SIX':'EIGHT',\n",
    "            'EIGHT':'TWO'\n",
    "        },\n",
    "        filter_thr=GW_THR,\n",
    "        feedback=PROC_FDBCK, npd_AM=npd_AM, broadcast_source=broadcast_source, seed=seed\n",
    "    )\n",
    "    \n",
    "    # An associative memory for the - operation\n",
    "    SUB = Processor(\n",
    "        vocab, vocab_GW, 'SUB', add_ON=add_ON,\n",
    "        AM_mapping = {\n",
    "            'TWO':'EIGHT',\n",
    "            'FOUR':'TWO',\n",
    "            'SIX':'FOUR',\n",
    "            'EIGHT':'SIX'\n",
    "        },\n",
    "        filter_thr=GW_THR,\n",
    "        feedback=PROC_FDBCK, npd_AM=npd_AM, broadcast_source=broadcast_source, seed=seed\n",
    "    )\n",
    "    \n",
    "    # An associative memory for the \"compare to 5\" operation\n",
    "    COM = Processor(\n",
    "        vocab, vocab_GW, 'COM', add_ON=add_ON,\n",
    "        AM_mapping = {\n",
    "            'TWO':'LESS',\n",
    "            'FOUR':'LESS',\n",
    "            'SIX':'MORE',\n",
    "            'EIGHT':'MORE'\n",
    "        },\n",
    "        filter_thr=GW_THR,\n",
    "        filter_mapping=['MORE','LESS'],\n",
    "        feedback=PROC_FDBCK, npd_AM=npd_AM, broadcast_source=broadcast_source, seed=seed\n",
    "    )\n",
    "\n",
    "    # A slot that combines selected information from the processors\n",
    "    GW = spa.State(vocab_GW, label='GW', feedback=GW_FDBCK)\n",
    "    \n",
    "    processors = [V, ADD, SUB, COM]\n",
    "    for p in processors:\n",
    "        if p.sender:\n",
    "            p.filter >> GW\n",
    "    \n",
    "    # access network\n",
    "    access_labels = []\n",
    "    with spa.Network(label='conscious access') :\n",
    "        with spa.ActionSelection() as access:\n",
    "            for p in processors:\n",
    "                if p.sender:\n",
    "                    access_labels.append(p.label)\n",
    "                    spa.ifmax(p.label, ROUTING_BIAS+spa.dot(p.preconscious, s.ON)*p.attention,\n",
    "                                p.preconscious >> p.filter.input,\n",
    "                             )\n",
    "            access_labels.append(\"Thresholder\")\n",
    "            spa.ifmax(ROUTING_BIAS+ROUTING_THR)   \n",
    "    \n",
    "    # broadcast network\n",
    "    action_labels = []\n",
    "    with spa.Network(label='broadcast') :\n",
    "        with spa.ActionSelection() as broadcast:\n",
    "\n",
    "            action_labels.append(\"V_COM\")\n",
    "            spa.ifmax(\"V_COM\", ROUTING_BIAS+spa.dot(V.filter, s.V*s.ON) * spa.dot(G, s.SIMPLE),\n",
    "                          V.broadcast_source >> COM.input_state,\n",
    "                          *(+1/2 >> p.attention if p==COM else -1/2 >> p.attention for p in processors)\n",
    "                     )\n",
    "\n",
    "            action_labels.append(\"V_SUB\")\n",
    "            spa.ifmax(\"V_SUB\", ROUTING_BIAS+spa.dot(V.filter, s.V*s.ON) * spa.dot(G, s.CHAINED_SUB),\n",
    "                          V.broadcast_source >> SUB.input_state,\n",
    "                          *(+1/2 >> p.attention if p==SUB else -1/2 >> p.attention for p in processors)\n",
    "                     )\n",
    "\n",
    "            action_labels.append(\"V_ADD\")\n",
    "            spa.ifmax(\"V_ADD\", ROUTING_BIAS+spa.dot(V.filter, s.V*s.ON) * spa.dot(G, s.CHAINED_ADD),\n",
    "                          V.broadcast_source >> ADD.input_state,\n",
    "                          *(+1/2 >> p.attention if p==ADD else -1/2 >> p.attention for p in processors)\n",
    "                     )\n",
    "\n",
    "            action_labels.append(\"ADD_COM\")\n",
    "            spa.ifmax(\"ADD_COM\", ROUTING_BIAS+spa.dot(ADD.filter, s.ADD*s.ON),\n",
    "                          ADD.broadcast_source >> COM.input_state,\n",
    "                          *(+1/2 >> p.attention if p==COM else -1/2 >> p.attention for p in processors)\n",
    "                     )\n",
    "\n",
    "            action_labels.append(\"SUB_COM\")\n",
    "            spa.ifmax(\"SUB_COM\", ROUTING_BIAS+spa.dot(SUB.filter, s.SUB*s.ON),\n",
    "                          SUB.broadcast_source >> COM.input_state,\n",
    "                          *(+1/2 >> p.attention if p==COM else -1/2 >> p.attention for p in processors)\n",
    "                     )\n",
    "\n",
    "            action_labels.append(\"COM_PM\")\n",
    "            spa.ifmax(\"COM_PM\", ROUTING_BIAS+spa.dot(COM.filter, s.COM*s.ON),\n",
    "                          COM.broadcast_source >> PM,\n",
    "                          *(-1/2 >> p.attention for p in processors)\n",
    "                     )            \n",
    "\n",
    "            action_labels.append(\"Thresholder\")\n",
    "            spa.ifmax(\"Thresholder\", ROUTING_BIAS+ROUTING_THR) # Threshold for action\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    \n",
    "    probe_dt = .05\n",
    "    probe_synapse = .015\n",
    "    p_V = nengo.Probe(V.input_state.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    p_G = nengo.Probe(G.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "\n",
    "    p_GW = nengo.Probe(GW.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "\n",
    "    p_ADD = nengo.Probe(ADD.input_state.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    p_SUB = nengo.Probe(SUB.input_state.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    p_COM = nengo.Probe(COM.input_state.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    \n",
    "    p_PM = nengo.Probe(PM.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    p_ACT = nengo.Probe(ACT.output, synapse = probe_synapse)#, sample_every = probe_dt)\n",
    "    p_BTN = nengo.Probe(BTN)#, sample_every = probe_dt)\n",
    "    \n",
    "    p_broadcast_in = nengo.Probe(broadcast.bg.input, synapse = probe_synapse)\n",
    "    p_broadcast_out = nengo.Probe(broadcast.bg.output, synapse = probe_synapse)\n",
    "    p_access_in = nengo.Probe(access.bg.input, synapse = probe_synapse)\n",
    "    p_access_out = nengo.Probe(access.bg.output, synapse = probe_synapse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt = .001\n",
    "print(\"Number of neurons:\", model.n_neurons)\n",
    "print(\"T:\",T)\n",
    "with simulator(model, dt = dt, seed=seed) as sim:\n",
    "    sim.run(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    \n",
    "    def plot_similarities(t_range, data, vocab, keys=False, autoscale=False, title='Similarity', sort_legend=True, permutation=None, subplot_nrows=0, subplot_ncols=0, subplot_i = 1):\n",
    "\n",
    "        if not keys:\n",
    "            keys = list(vocab.keys())\n",
    "\n",
    "        if subplot_nrows * subplot_ncols > 0:\n",
    "            plt.subplot(subplot_nrows,subplot_ncols,subplot_i)\n",
    "\n",
    "        if permutation is None:\n",
    "            permutation = range(vocab.dimensions)\n",
    "        vectors = np.array([vocab.parse(p).v @ np.identity(vocab.dimensions)[permutation] for p in keys])\n",
    "        mean_activation = spa.similarity(data, vectors).mean(axis=0)\n",
    "        sort_idx = np.argsort(mean_activation)[::-1]    \n",
    "\n",
    "        ymin, ymax = -1.5, 1.5\n",
    "        plt.ylim(ymin, ymax)\n",
    "        plt.autoscale(autoscale, axis='y')\n",
    "        plt.grid(True)\n",
    "        plt.plot(t_range, spa.similarity(data, vectors[sort_idx]), linewidth=2.5)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Similarity\")\n",
    "        plt.xlim(left=t_range[0], right=t_range[-1])\n",
    "        plt.xticks(np.arange(t_range[0], t_range[-1], xp.trial_length))\n",
    "        leg = plt.legend([str(round(mean_activation[sort_idx][i],2))+' '+k for i,k in enumerate(np.array(keys)[sort_idx])], loc='upper center',\n",
    "                   bbox_to_anchor=(0.5, -0.13), ncol=3)\n",
    "        \n",
    "        # set the linewidth of each legend object\n",
    "        for legobj in leg.legendHandles:\n",
    "            legobj.set_linewidth(4.0)\n",
    "            \n",
    "        if subplot_nrows * subplot_ncols == 0:\n",
    "            plt.show()\n",
    "\n",
    "        return subplot_i + 1\n",
    "\n",
    "\n",
    "\n",
    "    subplot_nrows=9\n",
    "    subplot_ncols=1\n",
    "    plt.figure(figsize=(6*subplot_ncols,4.5*subplot_nrows))\n",
    "    \n",
    "    def trial_t(trial_number):\n",
    "        return trial_number*xp.trial_length\n",
    "    \n",
    "    focus_start = 0 # first trial to plot\n",
    "    n_focus = 3 # how many trials to plot\n",
    "    start = trial_t(focus_start)\n",
    "    end = trial_t(focus_start+n_focus)\n",
    "    skip = 5\n",
    "    trange = sim.trange()\n",
    "    selected_idx = np.where(np.logical_and(trange > start, trange < end))\n",
    "    trange = trange[selected_idx][::skip]\n",
    "\n",
    "\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_V][selected_idx][::skip], vocab, keys=['TWO','FOUR','SIX','EIGHT', 'ON','X'], title='V', subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_G][selected_idx][::skip], vocab, keys=['SIMPLE','CHAINED_SUB','CHAINED_ADD'], title='G', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_ADD][selected_idx][::skip], vocab, keys=['TWO','FOUR','SIX','EIGHT','ON','X'], title='ADD', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_SUB][selected_idx][::skip], vocab, keys=['TWO','FOUR','SIX','EIGHT','ON','X'], title='SUB', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_COM][selected_idx][::skip], vocab, keys=['MORE','LESS','ON'], title='COM', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_PM][selected_idx][::skip], vocab, keys=['MORE','LESS','ON'], title='PM', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_ACT][selected_idx][::skip], vocab, keys=['MORE','LESS','ON'], title='ACT', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "    subplot_i=plot_similarities(trange, sim.data[p_GW][selected_idx][::skip], vocab_GW, keys=[p+\"*ON\" for p in [\"G\", \"V\", \"ADD\", \"SUB\", \"COM\"]], title='GW', subplot_i=subplot_i, subplot_nrows=subplot_nrows, subplot_ncols=subplot_ncols)\n",
    "\n",
    "    trange = sim.trange()[selected_idx]\n",
    "    plt.subplot(subplot_nrows,subplot_ncols,subplot_i)\n",
    "    plt.plot(trange, sim.data[p_BTN][selected_idx], color='black', linewidth=3.5)\n",
    "    plt.xlim(left=trange[0], right=trange[-1])\n",
    "    plt.xticks(np.arange(trange[0], trange[-1], xp.trial_length))\n",
    "    plt.ylim(-.2,2.2)\n",
    "    plt.ylabel(\"Action\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "for i in range(broadcast.bg.input.size_out):\n",
    "    plt.subplot(1,broadcast.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_broadcast_in][:,i][selected_idx][::skip])\n",
    "    plt.title(action_labels[i])\n",
    "    plt.ylim(-.5,1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "for i in range(broadcast.bg.input.size_out):\n",
    "    plt.subplot(1,broadcast.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_broadcast_out][:,i][selected_idx][::skip])\n",
    "    plt.title(action_labels[i])\n",
    "    plt.ylim(-1.5,.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "for i in range(access.bg.input.size_out):\n",
    "    plt.subplot(1,access.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_access_in][:,i][selected_idx][::skip])\n",
    "    plt.title(access_labels[i])\n",
    "    plt.ylim(-.5,1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,12))\n",
    "for i in range(access.bg.input.size_out):\n",
    "    plt.subplot(1,access.bg.input.size_out,i+1)\n",
    "    plt.plot(sim.trange()[selected_idx][::skip], sim.data[p_access_out][:,i][selected_idx][::skip])\n",
    "    plt.title(access_labels[i])\n",
    "    plt.ylim(-1.5,.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_key_to_int = {'TWO':2, 'FOUR':4, 'SIX':6, 'EIGHT':8}\n",
    "digit_key_to_idx = {k:i for i,k in enumerate(digit_key_to_int.keys())}\n",
    "operations_key_to_idx = {k:i for i,k in enumerate(['SIMPLE', 'CHAINED_ADD', 'CHAINED_SUB'])}\n",
    "\n",
    "n_per_condition = n_blocks_per_operation * n_trials_per_digit\n",
    "\n",
    "RTs = np.zeros((n_different_operations, n_different_digits, n_per_condition)) \n",
    "performance = np.zeros((n_different_operations, n_different_digits, n_per_condition)) # 0:no answer / 1:wrong answer / 2:correct answer\n",
    "xp_errors = []\n",
    "\n",
    "indices = np.zeros((n_different_operations, n_different_digits), dtype=int) \n",
    "\n",
    "\n",
    "def get_expected_action(trial):\n",
    "    N = digit_key_to_int[trial.stimulus] \n",
    "    if trial.operation == 'CHAINED_ADD':\n",
    "        N += 2\n",
    "    elif trial.operation == 'CHAINED_SUB':\n",
    "        N -= 2\n",
    "    if N > 8:\n",
    "        N = 2\n",
    "    elif N < 2:\n",
    "        N = 8\n",
    "    expected_action = 1 + int(not N > 5)\n",
    "    return expected_action\n",
    "\n",
    "t = 0\n",
    "while t<T-.01:\n",
    "    t += xp.trial_length\n",
    "    trial = xp(t)[0]\n",
    "    expected_action = get_expected_action(trial)\n",
    "    t_window = (np.where(np.logical_and(sim.trange() < t, sim.trange() > t-xp.trial_length))[0],)\n",
    "    \n",
    "    # get model's action\n",
    "    model_behaviour = sim.data[p_BTN][t_window]\n",
    "    if np.count_nonzero(model_behaviour) > 1:\n",
    "        raise ValueError(\"more than one action\")\n",
    "    \n",
    "    \n",
    "    cond_idx = (operations_key_to_idx[trial.operation], digit_key_to_idx[trial.stimulus])\n",
    "    trial_idx = indices[cond_idx]\n",
    "    \n",
    "    model_action = model_behaviour.sum()\n",
    "    if model_action == 0:\n",
    "        trial_RT = 0\n",
    "        trial_performance = 0\n",
    "    else:\n",
    "        action_t_idx = np.nonzero(model_behaviour[:,0])\n",
    "        trial_RT = sim.trange()[t_window][action_t_idx][0] - (t-xp.trial_length) - xp.t_start\n",
    "        trial_performance = int(model_action==expected_action) + 1\n",
    "    \n",
    "    xp_errors += [trial_performance!=2]\n",
    "    \n",
    "    performance[cond_idx+(trial_idx,)] = trial_performance\n",
    "    RTs[cond_idx+(trial_idx,)] = trial_RT\n",
    "    \n",
    "    indices[cond_idx] += 1 # increment index of this condition\n",
    "    \n",
    "\n",
    "\n",
    "xp_errors = np.array(xp_errors, dtype=bool)\n",
    "\n",
    "plt.figure(figsize=(8,1))\n",
    "plt.eventplot(np.where(xp_errors), color='black')\n",
    "plt.yticks([])\n",
    "plt.ylabel('Error')\n",
    "plt.xlim(-1,len(xp_errors)+1)\n",
    "plt.title('Score: '+str(number_of_total_trials-xp_errors.sum())+'/'+str(number_of_total_trials)+\"\\n\"+\n",
    "         \"error rate: \"+str(round(100*xp_errors.sum()/number_of_total_trials,2))+\"%\")\n",
    "plt.xlabel('Trial')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(indices)\n",
    "# print(RTs)\n",
    "print(performance.shape)\n",
    "print(performance[:,3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple blocks plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RTs_simple = np.copy(RTs[0,:,:]) * 1000\n",
    "RTs_simple = [RTs_simple[i,:] for i in range(n_different_digits)]\n",
    "print(RTs_simple)\n",
    "for digit_RTs in RTs_simple:\n",
    "#     print(digit_RTs.shape)\n",
    "    digit_RTs = digit_RTs[digit_RTs != 0] # remove outliers (no answer)\n",
    "#     print(digit_RTs.shape)\n",
    "#     print('\\n')\n",
    "\n",
    "RTs_simple_median = np.array([np.median(digit_RTs) for digit_RTs in RTs_simple])\n",
    "RTs_simple_std = np.array([digit_RTs.std() for digit_RTs in RTs_simple])\n",
    "plt.errorbar([2,4,6,8][:n_different_digits], RTs_simple_median, yerr=RTs_simple_std, color='black', capsize=3, capthick=2, marker='.', markersize=12, markerfacecolor='white')\n",
    "plt.ylabel('Median Reaction times (ms)')\n",
    "plt.xlabel('Stimuli')\n",
    "plt.xticks([2,4,6,8][:n_different_digits])\n",
    "plt.show()\n",
    "\n",
    "print(RTs_simple_median)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for unresponsive_as_error in [False,True]:\n",
    "\n",
    "    if unresponsive_as_error:\n",
    "        performance_simple = np.copy(performance[0,:,:])\n",
    "        err_simple = np.sum(performance_simple != 2, axis=1) / n_per_condition * 100\n",
    "        plt.title('Errors and absence of response')\n",
    "        \n",
    "    else:\n",
    "        performance_simple = np.copy(performance[0,:,:])\n",
    "        n_responsive = np.sum(performance_simple!=0) # count the number of responses\n",
    "        err_simple = np.sum(performance_simple == 1, axis=1) / n_responsive * 100\n",
    "        plt.title('Errors')\n",
    "\n",
    "    plt.bar([2,4,6,8][:n_different_digits], err_simple, color='black')\n",
    "    plt.ylabel('Error rates (%)')\n",
    "    plt.xlabel('Stimuli')\n",
    "    plt.xticks([2,4,6,8][:n_different_digits])\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained blocks plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
